---
title: "Dirichlet Processes"
output: html_notebook
---

## Sethuraman's construction of the Dirichlet process - stick-breaking definition

Simulation of trajectories of a Dirichlet process with parameter $(a, \alpha_0)$
  
Truncation of the infinite series and renormalization of the weights in Sethuraman's representation

We fix the mean trajectory $\alpha_0$ equal to the standard Gaussian

We see what happens to the trajectories of the *truncated* DP as $a=1,100, 0.1$

```{r}
a=1 ##### TOTAL MASS parameter 

M <- 500 # truncation level   M=1000 o M=500

install.packages("gsl")
install.packages(c("rbiutils", "gmp", "sets", "mathjaxr", "Rdpack", "Brobdingnag", "partitions", "polynom"))




```

$Y$ is the vector of the iid beta proportions in the stick-breaking

$\tau$ contains the support points of the DP, i.e. the $\tau_i$'s are iid from $\alpha_0={\mathcal N}(0,1)$

$V$ is the vector of the weights of the support points $\tau_i$'s

```{r}

install.packages("untb")

Y <- vector(length=M)    
tau <-  vector(length=M)  
V <- vector(length=M)     

```

#### Simulation of the (truncated) trajectories

$P_M:= \sum_{j=1}^M \dfrac{V_j}{\sum_{j=1}^M V_j}\delta_{\tau_j}= \sum_{j=1}^M \widetilde V_j \delta_{\tau_j}$

```{r}
set.seed(13)  # let's fix the seed

Y <- rbeta(M,1,a) # Y_i's are beta(1,a)-distributed
tau <- rnorm(M,0,1) # simulated tau_i 
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod   ## V_i = Y_i \prod_{j=1}^{i-1}(1-Y_j)  
                        
print(sum(V))  ## Compute the sum of all weights so far
V <- V/sum(V)  ## Rinormalization of the weights (needed because truncation of the infinite series)


```

VISUALIZATION of the support points $(\tau_i)_{i\geq 1}$ and the weights $(V_i)_{i\geq 1}$, and $\alpha_0$

```{r}
curve(dnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,ylim=c(0,0.5),xlab=" ",ylab="",cex.axis=1.5) #mean parameter alpha_0 (in magenta) 
abline(h=0,lty=2)
lines(tau,V,"h",lwd=3,col="red")
title("Weights and support points \nfor a simulated trajectory of a DP \n ")

```

When $a$ is SMALL, there is one SINGLE LARGE weight (about 1); all the other weights are almost 0, so that we do NOT see them in the plot

When $a$ is LARGE, all the weights $V_i$'s are small, and their values are very similar

```{r}
sort(V,decreasing=T)[1:50]
```

VISUALIZATION of the trajectory of the corresponding distribution function - it is easier to plot a df than a probability measure!

```{r}
oth <- order(tau)

curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,xlab=" ",ylab="",cex.axis=1.5) #magenta denotes the d.f. associated to alpha_0 
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="red",lwd=3)
title("Simulated trajectory of the DP distribution function")

```

TWO more trajectories

```{r}
oth <- order(tau)
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,xlab=" ",ylab="",cex.axis=1.5) #magenta denotes the d.f. associated to alpha_0 
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="red",lwd=3)
title("Simulated trajectory of the DP distribution function")

set.seed(99)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="green",lwd=3)

set.seed(76)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="blue",lwd=3)

```
```{r}
oth <- order(tau)
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,xlab=" ",ylab="",cex.axis=1.5) #magenta denotes the d.f. associated to alpha_0 
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="red",lwd=3)
title("Simulated trajectory of the DP distribution function")

set.seed(99)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="green",lwd=3)

set.seed(76)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="blue",lwd=3)

### SAMPLING MANY trajectories of the DP df: we add them to the same plot 
 gra=gray(1:100/100)
 gra=rep(gra,10)

for(j in 1:200){
set.seed(j)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col=gra[j])
}
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,add=T)
```
What if we change the value of a?? a=0.1, a=100

Pay attention to sum(V)!

### Comparison of simulated trajectories for 3 different values of $a$ 
```{r}
a=0.5

M <- 500 #truncation level  M=500
Y <- vector(length=M)  
tau <-  vector(length=M)  
V <- vector(length=M) 
 
Y <- rbeta(M,1,a) 
tau <- rnorm(M,0,1)    
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod  
print(sum(V))   
V <- V/sum(V)   

 
par(mfrow=c(1,3))
oth <- order(tau)
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,xlab="",ylab="",cex.axis=1.5)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="red",lwd=3)
title("Total mass a=0.5")
gra=gray(1:100/100)
gra=rep(gra,10)

for(j in 1:50){    
set.seed(j)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col=gra[j])
}
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,add=T)

##
a=5
M <- 500 # truncation level   M=500
Y <- vector(length=M)  
tau <-  vector(length=M)  
V <- vector(length=M) 
 
Y <- rbeta(M,1,a) #simulation of the beta rvs
tau <- rnorm(M,0,1) # tau_i iid from alpha_0= N(0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod  
print(sum(V))   
V <- V/sum(V)   


oth <- order(tau)
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,xlab="",ylab="",cex.axis=1.5)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="red",lwd=3)
title("Total mass a=5")
gra=gray(1:100/100)
gra=rep(gra,10)

for(j in 1:50){    
set.seed(j)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col=gra[j])
}
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,add=T)



##
a=50
M <- 500 #  
Y <- vector(length=M)  
tau <-  vector(length=M)  
V <- vector(length=M) 
 
Y <- rbeta(M,1,a)  
tau <- rnorm(M,0,1)  
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod  
print(sum(V))   
V <- V/sum(V)   


oth <- order(tau)
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,xlab="",ylab="",cex.axis=1.5)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col="red",lwd=3)
title("Total mass a=50")
gra=gray(1:100/100)
gra=rep(gra,10)

for(j in 1:50){     
set.seed(j)
Y <- rbeta(M,1,a)
tau <- rnorm(M,0,1)
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod
print(sum(V))
V <- V/sum(V)
oth <- order(tau)
lines(c(min(tau)-100,tau[oth],max(tau)+100),c(0,cumsum(V[oth]),1),type="s",col=gra[j])
}
curve(pnorm(x,0,1),from=-4,to=4,col="magenta",lwd=2,add=T,xlab="",ylab="",cex.axis=1.5)

```
***  

## DIRECT sampling from a Dirichlet process

We simulate $Y_i$ iid from a truncated trajectory $P_M$
```{r}
a=1
M <- 100 
Y <- vector(length=M)  
tau <-  vector(length=M)  
V <- vector(length=M) 
# Simulation
Y <- rbeta(M,1,a)  
tau <- rnorm(M,0,1)  
cprod <- cumprod(1-Y)
cprod  <- c(1,cprod[1:M-1])
V <- Y*cprod  
print(sum(V))   
V <- V/sum(V)
round(V,6)
```
Once that I have simulated the trajectory $P_M(\omega)$, I simulate an iid sample of size $n$ from $P_M(\omega)$

```{r}
n=10 ## sample size  
theta<-vector(length=n)
index <-vector(length=n)
for(j in 1:n){
  index[j] <- sample(1:M,size=1,prob=V) #sample one item
               # without replacement 
  theta[j]=tau[index[j]]
}
index
theta

```

```{r}
unique(theta)
```


Try different values of $n$ and $a$

***   
## GENERALIZED POLYA URN

We could simulate a sample from a Dirichlet process $Y_1,\ldots,Y_n$ by   
- (i) first simulating a (truncated) stick-breaking trajectory of a Dirichlet process $P_M$  
- (ii) then simulating $Y_1,\ldots,Y_n$  iid from $P_M$, as we have done above
 
However, we could use a DIRECT sampling scheme GENERALIZED POLYA URN

```{r}
a=1  #0.1, 1,  100

n=10 ## sample size ##n=2, 5, 10, 100, 697
theta<-vector(length=n) #simulated values: I rename it theta instead than Y

theta[1] <- rnorm(1) #first simulated value from alpha_0 = N(0,1)

```

```{r}
?sample
```

From the second simulated value, we get 
a NEW observation from $\alpha_0$ with probability $w_0$
or an OLD observation, each of the old obs with prob $w_1$

```{r}
for(j in 2:n){ ## from the second simulated value, we get 
w0<- a/(j-1+a) ## a NEW observation from alpha_0 with probability w0
w1<-rep(1/(j-1+a),j-1) ## or an OLD observation, each of the old obs with prob w1

index <- sample(0:(j-1),size=1,prob=c(w0,w1)) 
# Sample the index from a discrete distribution with weights 
#   contained in the vector prob, i.e. sample from the categorical distr.
if(index==0){
	theta[j] <- rnorm(1) # NEW observation
}
else{
	theta[j]=theta[index] # OLD observation 
}
}

theta
```
```{r}
unique(theta)
```
$K_n$: number of UNIQUE values in the sample theta
```{r}
k <- length(unique(theta))
k
```
Let's use Monte Carlo to plot this discrete density 
```{r}
k <- vector(length=5000)
set.seed(19)
for(i in 1:5000){ ##Sampling from the generalized Polya urn repeatedly
      ##################################
	##################################
	theta[1] <- rnorm(1)
	for(j in 2:n){
		w0<-a/(j-1+a)
		w1<-rep(1/(j-1+a),j-1)
		index <- sample(0:(j-1),size=1,prob=c(w0,w1))
		if(index==0){
			theta[j] <- rnorm(1)
		}
		else{
			theta[j]=theta[index]
		}
	}
        ###########################
	###########################
	k[i] <- length(unique(theta))
}

k
ymax=max(table(k)/5000)+0.01

plot(table(k)/5000,ylim=c(0,ymax),ylab="")
title("Prior probability of the number of clusters")
 

# Compare this MC distribution to the "exact" one - Antoniak 1974 (Ewens formula)
library(gsl) # library gsl to compute log of the Gamma function  lngamma
library(untb) # library containing logS1 
#logS1[] e' una matrice che contiene il logaritmo dei numeri di Stirling di primo tipo  
# di primo tipo sulla matrice [1:100]*[1:100]
## dato che n=100 la possiamo  utilizzare

pk <- vector(length=n) ## EXACT (analytic) probability                           #  density of K_n  in the log scale
cost.a <- lngamma(a)-lngamma(a+n)  
for(l in 1:n){
pk[l] <- logS1[n,l]+l*log(a)+cost.a #logaritmo di pk
}

pk=exp(pk) #probabilities in teh original scale  
points(1:n,pk,type="b",col="red",lty=2) # let's plot the  probability masses of the exact distribution of $K_n$  

```
Expectation of $K_n$ 

```{r}

meanKn= a *sum(1/( a+seq(0,n-1))) # computed via its analytic expression 
meanKn
sum(seq(1:n)*pk) # Monte Carlo approximation
```

How does this distribution change varying $n$ or/and $a$?

When $a$ is SMALL (e.g. $a=0.1$), the sample from the DP yields a few unique values, i.e. the distribution of K_n is concentrated on small values, close to 1

When $a$ is LARGE (e.g. $a=100$), the sample from the DP has may small jumps so that we get larger values for $K_n$

